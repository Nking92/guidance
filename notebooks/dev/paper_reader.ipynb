{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from pdfminer.high_level import extract_text\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tokens(text: str):\n",
    "    # Encoding for GPT-3 and later models\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    tokens = encoding.encode(text, disallowed_special=())\n",
    "    num_tokens = len(tokens)\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the PDF\n",
    "Let's read the PDF and see how many tokens it has. We'll also print out a snippet to see what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF file has 87764 chars, 24231 tokens\n",
      "Yi: Open Foundation Models by 01.AI\n",
      "\n",
      "01.AI\n",
      "\n",
      "Code: https://github.com/01-ai/Yi\n",
      "Model: https://huggingface.co/01-ai\n",
      "\n",
      "Abstract\n",
      "\n",
      "We introduce the Yi model family, a series of language and multimodal models that\n",
      "demonstrate strong multi-dimensional capabilities. The Yi model family is based\n",
      "on 6B and 34B pretrained language models, then we extend them to chat models,\n",
      "200K long context models, depth-upscaled models, and vision-language models.\n",
      "Our base models achieve strong performance on a wide range of benchmarks like\n",
      "MMLU, and our finetuned chat models deliver strong human preference rate on\n",
      "major evaluation platforms like AlpacaEval and Chatbot Arena. Building upon our\n",
      "scalable super-computing infrastructure and the classical transformer architecture,\n",
      "we attribute the performance of Yi models primarily to its data quality resulting\n",
      "from our data-engineering efforts. For pretraining, we construct 3.1 trillion tokens\n",
      "of English and Chinese corpora using a cascaded data deduplication and qu...\n"
     ]
    }
   ],
   "source": [
    "pdf_path = '/Users/nicholasking/Library/CloudStorage/OneDrive-Personal/Computer Science/Papers/ML/Yi- Open Foundation Models by 01AI.pdf'\n",
    "pdf_text = extract_text(pdf_path)\n",
    "\n",
    "print(f\"PDF file has {len(pdf_text)} chars, {count_tokens(pdf_text)} tokens\")\n",
    "print(pdf_text[:1000] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize the PDF with an Guidance\n",
    "Next, we'll prompt an LLM to generate a summary of the PDF using Guidance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from guidance import models\n",
    "\n",
    "azure_model = os.getenv(\"AZUREAI_CHAT_MODEL\", \"Please set the model\")\n",
    "azure_endpoint = os.getenv(\"AZUREAI_CHAT_ENDPOINT\", \"Please set the endpoint\")\n",
    "azure_api_key=os.getenv(\"AZUREAI_CHAT_KEY\", \"Please set API key\")\n",
    "\n",
    "gpt4 = models.AzureOpenAI(\n",
    "    model=azure_model,\n",
    "    azure_endpoint=azure_endpoint,\n",
    "    api_key=azure_api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from guidance import system, user, assistant, gen\n",
    "\n",
    "gpt4_summary = gpt4.copy()\n",
    "\n",
    "with system():\n",
    "    gpt4_summary += \"You are a reading and summarization assistant.\"\n",
    "\n",
    "with user():\n",
    "    gpt4_summary += f\"Please summarize the following machine learning paper for me.\\n\\n{pdf_text}\"\n",
    "\n",
    "with assistant():\n",
    "    gpt4_summary += gen(max_tokens=2000, temperature=0.7)\n",
    "\n",
    "gpt4_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the paper as HTML\n",
    "Try reading the paper using HTML layout and see how it changes the quality of the summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pdf_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpdfminer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayout\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LAParams\n\u001b[1;32m      4\u001b[0m html_stringio \u001b[38;5;241m=\u001b[39m StringIO()\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[43mpdf_path\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fin:\n\u001b[1;32m      6\u001b[0m     extract_text_to_fp(fin, html_stringio, laparams\u001b[38;5;241m=\u001b[39mLAParams(),\n\u001b[1;32m      7\u001b[0m                        output_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml\u001b[39m\u001b[38;5;124m'\u001b[39m, codec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m      9\u001b[0m html_string \u001b[38;5;241m=\u001b[39m html_stringio\u001b[38;5;241m.\u001b[39mgetvalue()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pdf_path' is not defined"
     ]
    }
   ],
   "source": [
    "from io import StringIO\n",
    "from pdfminer.high_level import extract_text_to_fp\n",
    "from pdfminer.layout import LAParams\n",
    "html_stringio = StringIO()\n",
    "with open(pdf_path, 'rb') as fin:\n",
    "    extract_text_to_fp(fin, html_stringio, laparams=LAParams(),\n",
    "                       output_type='html', codec=None)\n",
    "\n",
    "html_string = html_stringio.getvalue()\n",
    "\n",
    "print(f\"PDF -> HTML has {len(html_string)} chars, {count_tokens(html_string)} tokens\")\n",
    "print(html_string[:1000] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are too many tokens in the HTML, so we need to clean it up\n",
    "# Also see: https://python.langchain.com/docs/modules/data_connection/document_loaders/pdf#using-pdfminer-to-generate-html-text\n",
    "\n",
    "from bs4 import BeautifulSoup, NavigableString, Comment\n",
    "\n",
    "def is_empty_element(elem):\n",
    "    if isinstance(elem, (NavigableString, Comment)):\n",
    "        # Skip NavigableString and Comment objects; they're not containers\n",
    "        return False\n",
    "    # Check if a tag is empty or contains only whitespace\n",
    "    text_content = ''.join(elem.stripped_strings)\n",
    "    return not text_content and all(is_empty_element(child) for child in elem.children)\n",
    "\n",
    "def remove_empty_elements(soup):\n",
    "    for elem in list(soup.find_all(True)):  # Find all tags\n",
    "        if is_empty_element(elem) and elem.name != 'body':  # Avoid removing the body tag\n",
    "            elem.decompose()\n",
    "\n",
    "def minify_html(html_string):\n",
    "    # Assuming `html_string` is your original HTML content\n",
    "    soup = BeautifulSoup(html_string, 'html.parser')\n",
    "\n",
    "    # Remove all <br> tags\n",
    "    for br in soup.find_all(\"br\"):\n",
    "        br.decompose()\n",
    "\n",
    "    # Iterate over all tags and clear their attributes\n",
    "    for tag in soup.find_all(True):\n",
    "        tag.attrs = {}\n",
    "\n",
    "    # Remove empty elements\n",
    "    remove_empty_elements(soup)\n",
    "\n",
    "    # Convert the soup object back to a string without extra attributes, without <br> tags, and without empty elements\n",
    "    return str(soup)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minified_html = minify_html(html_string)\n",
    "print(f\"Cleaned HTML has {len(minified_html)} chars, {count_tokens(minified_html)} tokens\")\n",
    "print(minified_html[:1000] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from guidance import system, user, assistant, gen\n",
    "\n",
    "gpt4_summary_html = gpt4.copy()\n",
    "\n",
    "with system():\n",
    "    gpt4_summary_html += \"You are a reading and summarization assistant.\"\n",
    "\n",
    "with user():\n",
    "    gpt4_summary_html += f\"Please summarize the following machine learning paper for me.\\n\\n{minified_html}\"\n",
    "\n",
    "with assistant():\n",
    "    gpt4_summary_html += gen(max_tokens=2000, temperature=0.7)\n",
    "\n",
    "gpt4_summary_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML has 297354 chars, 114164 tokens\n",
      "<article class=\"ltx_document ltx_authors_1line\">\n",
      "<h1 class=\"ltx_title ltx_title_document\">Yi: Open Foundation Models by 01.AI </h1>\n",
      "<div class=\"ltx_authors\">\n",
      "<span class=\"ltx_creator ltx_role_author\">\n",
      "<span class=\"ltx_personname\">\n",
      "<span class=\"ltx_text ltx_font_bold\" id=\"id1.1.id1\">01.AI</span>\n",
      "<br class=\"ltx_break\"/>â \n",
      "<br class=\"ltx_break\"/><span class=\"ltx_text ltx_font_bold\" id=\"id2.2.id2\">Code:</span>â <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://github.com/01-ai/Yi\" tit\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the webpage to fetch\n",
    "url = \"https://arxiv.org/html/2403.04652v1\"\n",
    "\n",
    "# Fetch the HTML content of the webpage\n",
    "response = requests.get(url)\n",
    "html_content = response.text\n",
    "\n",
    "# Parse the HTML content\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# Select the <article> element and all its children\n",
    "article_element = soup.find('article')\n",
    "\n",
    "# Check if the article element exists and stringify it\n",
    "if article_element:\n",
    "    article_html = str(article_element)\n",
    "else:\n",
    "    article_html = \"Article element not found\"\n",
    "\n",
    "# article_html now contains the stringified HTML of the <article> element and its children\n",
    "print(f\"HTML has {len(article_html)} chars, {count_tokens(article_html)} tokens\")\n",
    "print(article_html[:500])  # Print the first 500 characters to verify\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned HTML has 123612 chars, 38154 tokens\n",
      "<article>\n",
      "<h1>Yi: Open Foundation Models by 01.AI </h1>\n",
      "<div>\n",
      "<span>\n",
      "<span>\n",
      "<span>01.AI</span>\n",
      "â \n",
      "<span>Code:</span>â <a>https://github.com/01-ai/Yi</a>\n",
      "<span>Model:</span>â <a>https://huggingface.co/01-ai</a>\n",
      "\n",
      "</span><span>\n",
      "<span>\n",
      "</span></span></span>\n",
      "</div>\n",
      "<div>\n",
      "<h6>Abstract</h6>\n",
      "<p>We introduce the Yi model family, a series of language and multimodal models that demonstrate strong multi-dimensional capabilities.\n",
      "The Yi model family is based on 6B and 34B pretrained language models, th...\n"
     ]
    }
   ],
   "source": [
    "article_minified_html = minify_html(article_html)\n",
    "print(f\"Cleaned HTML has {len(article_minified_html)} chars, {count_tokens(article_minified_html)} tokens\")\n",
    "print(article_minified_html[:500] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from guidance import system, user, assistant, gen\n",
    "\n",
    "gpt4_summary_html = gpt4.copy()\n",
    "\n",
    "with system():\n",
    "    gpt4_summary_html += \"You are a reading and summarization assistant.\"\n",
    "\n",
    "with user():\n",
    "    gpt4_summary_html += f\"Please summarize the following machine learning paper for me.\\n\\n{article_minified_html}\"\n",
    "\n",
    "with assistant():\n",
    "    gpt4_summary_html += gen(max_tokens=4000, temperature=0.9)\n",
    "\n",
    "gpt4_summary_html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with local model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "yi = models.LlamaCppChat(\"/Users/nicholasking/code/models/yi-34b-200k-llamafied.Q4_K_S.gguf\", n_gpu_layers=-1, n_ctx=64000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style='margin: 0px; padding: 0px; vertical-align: middle; padding-left: 8px; margin-left: -8px; border-radius: 0px; border-left: 1px solid rgba(127, 127, 127, 0.2); white-space: pre-wrap; font-family: ColfaxAI, Arial; font-size: 15px; line-height: 23px;'>Hello, <span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>world</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>!</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>/</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>n</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>\\</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>n</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>&quot;</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>;</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>\n",
       "</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>        </span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>assert</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>_</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>eq</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>!</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>(</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>\n",
       "</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>            </span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>format</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>!</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>(</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>&quot;</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>{:</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>u</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>}{</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>}&quot;</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>,</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> HE</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>LL</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>O</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>,</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> NAME</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>)</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>,</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>\n",
       "</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>            </span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>&quot;</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>Hello</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>,</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> world</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>!</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>\\</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>n</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>&quot;</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>\n",
       "</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>        </span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>);</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>\n",
       "</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>    </span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>}</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>\n",
       "</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>\n",
       "</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>    </span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>#[</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>test</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>]</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>\n",
       "</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>    </span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>fn</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> test</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>_</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>with</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>_</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>month</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>()</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> {</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>\n",
       "</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>        </span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>let</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> now</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> =</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> Na</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>ive</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>Date</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>::</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>from</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>_</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>ym</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>d</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>(</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>2</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>0</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>2</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>1</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>,</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> </span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>5</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>,</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> </span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>2</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>4</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>);</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>\n",
       "</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>        </span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>let</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> hello</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> =</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> &quot;</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>Hello</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>,</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>&quot;</span></pre>"
      ],
      "text/plain": [
       "<guidance.models.llama_cpp._llama_cpp.LlamaCppChat at 0xf8339c250>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yi + \"Hello, \" + gen(max_tokens=100, temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yi_chat = yi.copy()\n",
    "\n",
    "with system():\n",
    "    yi_chat += \"You are a reading and summarization assistant.\"\n",
    "\n",
    "with user():\n",
    "    yi_chat += f\"Please summarize the following machine learning paper for me.\\n\\n{article_minified_html}\"\n",
    "\n",
    "with assistant():\n",
    "    # Fails with error message that context window is too large\n",
    "    yi_chat += gen(max_tokens=500, temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
